import json
import logging
import hashlib
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.error import BadRequest
from telegram.ext import ContextTypes, ConversationHandler
from utils.api import call_danmaku_api
from utils.permission import check_user_permission
from utils.conversation_states import EPISODES_PER_PAGE, INPUT_EPISODE_RANGE, CALLBACK_DATA_MAX_LEN, IMPORT_AUTO_KEYWORD_INPUT, IMPORT_AUTO_ID_INPUT

# åˆå§‹åŒ–æ—¥å¿—
logger = logging.getLogger(__name__)


@check_user_permission
async def handle_import_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†ã€Œå¯¼å…¥æŒ‰é’®ã€çš„å›è°ƒäº‹ä»¶ï¼ˆdirect_importæ ¸å¿ƒé€»è¾‘ï¼‰"""
    query = update.callback_query
    logger.info(f"ğŸ“¥ æ”¶åˆ°å¯¼å…¥å›è°ƒæ•°æ®ï¼š{query.data}")
    
    # 1. è§£æå›è°ƒæ•°æ®
    try:
        callback_data = json.loads(query.data)
        action = callback_data.get("action")
        result_index = callback_data.get("result_index")
        
        if action != "import_media" or result_index is None:
            await query.answer("âŒ æ— æ•ˆçš„æ“ä½œè¯·æ±‚", show_alert=True)
            return
    except json.JSONDecodeError:
        await query.answer("âŒ æ•°æ®è§£æå¤±è´¥ï¼Œè¯·é‡è¯•", show_alert=True)
        return

    # 2. è¯»å–ä¸Šä¸‹æ–‡ä¿å­˜çš„searchId
    search_id = context.user_data.get("search_id", "")
    if not search_id:
        await query.answer("âŒ æœªæ‰¾åˆ°å†å²æœç´¢è®°å½•ï¼Œè¯·é‡æ–°æœç´¢", show_alert=True)
        return

    # 3. æŒ‰é’®åŠ è½½çŠ¶æ€æç¤ºï¼ˆå·²æ³¨é‡Šï¼Œæ ¹æ®ç”¨æˆ·è¦æ±‚ä¸å½±å“æŒ‰é’®å±•ç¤ºï¼‰
    # await query.answer("ğŸ”„ æ­£åœ¨å‘èµ·å¯¼å…¥è¯·æ±‚...", show_alert=False)

    # 4. è°ƒç”¨APIæ‰§è¡Œdirect_import
    api_result = call_danmaku_api(
        method="POST",
        endpoint="/import/direct",
        json_data={
            "searchId": search_id,
            "result_index": result_index,
        }
    )

    # 5. å¤„ç†å¯¼å…¥ç»“æœ
    if api_result["success"]:
        data = api_result["data"]
        task_id = data.get('taskId')
        
        # å‘é€ç»“æœé€šçŸ¥
        await query.message.reply_text(f"""
ğŸ‰ å¯¼å…¥è¯·æ±‚å·²æäº¤æˆåŠŸï¼
â€¢ ä»»åŠ¡IDï¼š{task_id or 'æ— '}
        """.strip())
        
        # å¦‚æœæœ‰taskIdï¼Œå¯åŠ¨è½®è¯¢å¹¶å‘é€å›è°ƒé€šçŸ¥
        if task_id:
            from utils.task_polling import bot_task_polling_manager
            
            # ä»ä¸Šä¸‹æ–‡è·å–æœç´¢ç»“æœ
            search_results = context.user_data.get("search_results", [])
            selected_result = search_results[result_index] if result_index < len(search_results) else {}
            
            # æ„å»ºåª’ä½“ä¿¡æ¯
            media_info = {
                'Type': selected_result.get('type', 'tv_series'),
                'Title': selected_result.get('title', ''),
                'Season': selected_result.get('season'),
            }
            
            # å‘é€å›è°ƒé€šçŸ¥å¹¶å¯åŠ¨è½®è¯¢
            await bot_task_polling_manager.send_callback_notification(
                operation_type="import",
                media_info=media_info,
                result="success",
                task_ids=[task_id],
                user_id=str(query.from_user.id),
                import_method="direct"  # æœç´¢åå¯¼å…¥ä¸ºdirectæ–¹å¼
            )
    else:
        # å‘é€å¤±è´¥åŸå› 
        await query.message.reply_text(f"""
âŒ å¯¼å…¥å¤±è´¥ï¼š{api_result['error']}
â€¢ å»ºè®®ï¼šè‹¥å¤šæ¬¡å¤±è´¥ï¼Œå¯å°è¯•é‡æ–°æœç´¢åå¯¼å…¥
        """.strip())


async def handle_import_auto_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†import_autoç›¸å…³çš„å›è°ƒ"""
    query = update.callback_query
    logger.info(f"ğŸ” æ”¶åˆ°import_autoå›è°ƒ: {query.data}")
    await query.answer()
    
    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºå­£åº¦é€‰æ‹©å›è°ƒï¼ˆéJSONæ ¼å¼ï¼‰
    if query.data.startswith("season_") or query.data == "cancel":
        logger.info(f"ğŸ“º å¤„ç†å­£åº¦é€‰æ‹©å›è°ƒ: {query.data}")
        # å¤„ç†å­£åº¦é€‰æ‹©å›è°ƒ
        from handlers.import_media import import_auto_season_selection
        return await import_auto_season_selection(update, context)
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºéimport_autoç›¸å…³çš„å›è°ƒæ•°æ®ï¼Œç›´æ¥è¿”å›
    if not query.data.startswith('{"action": "import_auto'):
        logger.info(f"ğŸ”„ éimport_autoå›è°ƒæ•°æ®ï¼Œè·³è¿‡å¤„ç†: {query.data}")
        return ConversationHandler.END
    
    # å°è¯•è§£æJSONæ ¼å¼çš„å›è°ƒæ•°æ®
    try:
        callback_data = json.loads(query.data)
        action = callback_data.get("action")
        
        if action == "import_auto_search_type":
            return await handle_search_type_selection(update, context, callback_data)
        elif action == "import_auto_media_type":
            return await handle_media_type_selection(update, context, callback_data)
        # elif action == "import_auto_method":
        #     return await handle_import_method_selection(update, context, callback_data)
        # elif action == "continue_season_import":
        #     return await handle_continue_season_import(update, context)
        # elif action == "continue_episode_import":
        #     return await handle_continue_episode_import(update, context, callback_data)
        elif action == "finish_import":
            return await handle_finish_import(update, context)
        else:
            await query.edit_message_text("âŒ æœªçŸ¥çš„æ“ä½œç±»å‹")
            return ConversationHandler.END
            
    except (json.JSONDecodeError, KeyError) as e:
        logger.error(f"è§£æimport_autoå›è°ƒæ•°æ®å¤±è´¥: {e}")
        await query.answer("âŒ æ— æ•ˆçš„å›è°ƒæ•°æ®")
        return ConversationHandler.END


async def handle_search_type_selection(update: Update, context: ContextTypes.DEFAULT_TYPE, callback_data: dict):
    """å¤„ç†æœç´¢ç±»å‹é€‰æ‹©"""
    query = update.callback_query
    search_type = callback_data.get("type")
    
    # ä¿å­˜æœç´¢ç±»å‹åˆ°ä¸Šä¸‹æ–‡
    context.user_data["import_auto_search_type"] = search_type
    
    if search_type == "keyword":
        # å…³é”®è¯æœç´¢ï¼šç›´æ¥æç¤ºè¾“å…¥å…³é”®è¯
        await query.edit_message_text(
            "ğŸ” **å…³é”®è¯æœç´¢**\n\n"
            "è¯·è¾“å…¥å½±è§†ä½œå“åç§°ï¼š\n\n"
            "ğŸ’¡ **æ™ºèƒ½åŠŸèƒ½**ï¼š\n"
            "â€¢ è‡ªåŠ¨è¯†åˆ«ç”µå½±/ç”µè§†å‰§ç±»å‹\n"
            "â€¢ ç”µè§†å‰§è‡ªåŠ¨æä¾›å­£åº¦é€‰æ‹©\n"
            "â€¢ æ”¯æŒä¸­è‹±æ–‡æœç´¢"
        )
        return IMPORT_AUTO_KEYWORD_INPUT
    else:
        # å¹³å°IDæœç´¢ï¼šç›´æ¥æç¤ºè¾“å…¥ID
        platform_names = {
            "tmdb": "TMDB",
            "tvdb": "TVDB", 
            "douban": "è±†ç“£",
            "imdb": "IMDB",
            "bangumi": "Bangumi"
        }
        platform_name = platform_names.get(search_type, search_type.upper())
        
        await query.edit_message_text(
            f"ğŸ†” **{platform_name} IDæœç´¢**\n\nè¯·è¾“å…¥{platform_name} IDæˆ–é“¾æ¥ï¼š"
        )
        
        return IMPORT_AUTO_ID_INPUT


async def handle_media_type_selection(update: Update, context: ContextTypes.DEFAULT_TYPE, callback_data: dict):
    """å¤„ç†åª’ä½“ç±»å‹é€‰æ‹©ï¼ˆç”¨äºå…³é”®è¯æœç´¢å’Œå¹³å°IDæœç´¢ï¼‰"""
    query = update.callback_query
    media_type = callback_data.get("type")
    
    # ä¿å­˜åª’ä½“ç±»å‹åˆ°ä¸Šä¸‹æ–‡
    context.user_data["import_auto_media_type"] = media_type
    
    type_names = {"tv_series": "ç”µè§†å‰§/åŠ¨æ¼«", "movie": "ç”µå½±"}
    type_name = type_names.get(media_type, media_type)
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰å…³é”®è¯ï¼ˆæ¥è‡ª /search å‘½ä»¤ï¼‰
    existing_keyword = context.user_data.get("import_auto_keyword")
    if existing_keyword:
        # å·²æœ‰å…³é”®è¯ï¼Œæ ¹æ®åª’ä½“ç±»å‹å†³å®šæµç¨‹
        if media_type == "movie":
            # ç”µå½±ç±»å‹ï¼šç›´æ¥å¯¼å…¥
            await query.edit_message_text(
                f"âœ… å·²é€‰æ‹©ï¼š{type_name}\nå…³é”®è¯ï¼š{existing_keyword}"
            )
            
            import_params = {
                "searchType": "keyword",
                "searchTerm": existing_keyword,
                "mediaType": media_type,
                "importMethod": "auto",
                "originalKeyword": existing_keyword  # ä¿å­˜åŸå§‹å…³é”®è¯ç”¨äºè¯†åˆ«è¯åŒ¹é…
            }
            
            from handlers.import_media import call_import_auto_api
            await call_import_auto_api(update, context, import_params)
            return ConversationHandler.END
        else:
            # ç”µè§†å‰§ç±»å‹ï¼šæ˜¾ç¤ºå¯¼å…¥æ–¹å¼é€‰æ‹©
            await query.edit_message_text(
                f"âœ… å·²é€‰æ‹©ï¼š{type_name}\nå…³é”®è¯ï¼š{existing_keyword}\n\nè¯·é€‰æ‹©å¯¼å…¥æ–¹å¼ï¼š"
            )
            
            # ä¿å­˜å¯¼å…¥å‚æ•°
            context.user_data["import_auto_params"] = {
                "searchType": "keyword",
                "searchTerm": existing_keyword,
                "mediaType": media_type,
                "originalKeyword": existing_keyword  # ä¿å­˜åŸå§‹å…³é”®è¯ç”¨äºè¯†åˆ«è¯åŒ¹é…
            }
            
            # æ˜¾ç¤ºå¯¼å…¥æ–¹å¼é€‰æ‹©
            from handlers.import_media import show_import_options
            return await show_import_options(update, context, context.user_data["import_auto_params"])
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰å¹³å°ID
    existing_id = context.user_data.get("import_auto_id")
    if existing_id:
        # å·²æœ‰å¹³å°IDï¼Œæ ¹æ®åª’ä½“ç±»å‹å†³å®šæµç¨‹
        search_type = context.user_data.get("import_auto_search_type", "tmdb")
        auto_detected_type = context.user_data.get("import_auto_media_type")
        
        # æ£€æŸ¥æ˜¯å¦ä¸è‡ªåŠ¨æ£€æµ‹çš„ç±»å‹ä¸ä¸€è‡´
        if auto_detected_type and auto_detected_type != media_type:
            detected_name = "ç”µå½±" if auto_detected_type == "movie" else "ç”µè§†å‰§/åŠ¨æ¼«"
            await query.edit_message_text(
                f"âš ï¸ **ç±»å‹ä¸ä¸€è‡´æé†’**\n\n"
                f"ğŸ” è‡ªåŠ¨æ£€æµ‹: {detected_name}\n"
                f"ğŸ‘¤ ç”¨æˆ·é€‰æ‹©: {type_name}\n\n"
                f"å°†æŒ‰ç”¨æˆ·é€‰æ‹©çš„ç±»å‹è¿›è¡Œå¯¼å…¥ã€‚\n\n"
                f"{'âœ… ç”µå½±ç±»å‹ç¡®è®¤' if media_type == 'movie' else 'è¯·é€‰æ‹©å¯¼å…¥æ–¹å¼ï¼š'}"
            )
        else:
            await query.edit_message_text(
                f"âœ… å·²é€‰æ‹©ï¼š{type_name}\nIDï¼š{existing_id}\n\n"
                f"{'âœ… ç”µå½±ç±»å‹ç¡®è®¤' if media_type == 'movie' else 'è¯·é€‰æ‹©å¯¼å…¥æ–¹å¼ï¼š'}"
            )
        
        if media_type == "movie":
            # ç”µå½±ç±»å‹ï¼šç›´æ¥å¯¼å…¥
            import_params = {
                "searchType": search_type,
                "searchTerm": existing_id,
                "mediaType": media_type,
                "importMethod": "auto",
                "originalKeyword": context.user_data.get("import_auto_keyword", "")  # ä¿å­˜åŸå§‹å…³é”®è¯ç”¨äºè¯†åˆ«è¯åŒ¹é…
            }
            
            from handlers.import_media import call_import_auto_api
            await call_import_auto_api(update, context, import_params)
            return ConversationHandler.END
        else:
            # ç”µè§†å‰§ç±»å‹ï¼šæ˜¾ç¤ºå¯¼å…¥æ–¹å¼é€‰æ‹©
            context.user_data["import_auto_params"] = {
                "searchType": search_type,
                "searchTerm": existing_id,
                "mediaType": media_type,
                "originalKeyword": context.user_data.get("import_auto_keyword", "")  # ä¿å­˜åŸå§‹å…³é”®è¯ç”¨äºè¯†åˆ«è¯åŒ¹é…
            }
            
            from handlers.import_media import show_import_options
            return await show_import_options(update, context, context.user_data["import_auto_params"])
    
    # æ—¢æ²¡æœ‰å…³é”®è¯ä¹Ÿæ²¡æœ‰IDï¼Œè¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿ
    await query.edit_message_text(
        "âŒ ç³»ç»Ÿé”™è¯¯ï¼šç¼ºå°‘æœç´¢å†…å®¹ï¼Œè¯·é‡æ–°å¼€å§‹ã€‚"
    )
    return ConversationHandler.END


async def handle_search_type_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ä¸“é—¨ç”¨äºConversationHandlerçš„æœç´¢ç±»å‹é€‰æ‹©å›è°ƒå¤„ç†å™¨"""
    query = update.callback_query
    await query.answer()
    
    try:
        callback_data = json.loads(query.data)
        if callback_data.get("action") == "import_auto_search_type":
            return await handle_search_type_selection(update, context, callback_data)
    except (json.JSONDecodeError, KeyError) as e:
        logger.error(f"è§£ææœç´¢ç±»å‹å›è°ƒæ•°æ®å¤±è´¥: {e}")
        await query.answer("âŒ æ— æ•ˆçš„å›è°ƒæ•°æ®")
    
    return ConversationHandler.END


async def handle_media_type_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ä¸“é—¨ç”¨äºConversationHandlerçš„åª’ä½“ç±»å‹é€‰æ‹©å›è°ƒå¤„ç†å™¨"""
    query = update.callback_query
    await query.answer()
    
    try:
        callback_data = json.loads(query.data)
        if callback_data.get("action") == "import_auto_media_type":
            return await handle_media_type_selection(update, context, callback_data)
    except (json.JSONDecodeError, KeyError) as e:
        logger.error(f"è§£æåª’ä½“ç±»å‹å›è°ƒæ•°æ®å¤±è´¥: {e}")
        await query.answer("âŒ æ— æ•ˆçš„å›è°ƒæ•°æ®")
    
    return ConversationHandler.END


# å·²ç§»é™¤handle_import_method_selectionå‡½æ•°ï¼Œå› ä¸ºä¸å†éœ€è¦å¯¼å…¥æ–¹å¼é€‰æ‹©


@check_user_permission
async def handle_get_episode_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    logger.info(f"ğŸ“¥ æ”¶åˆ°åˆ†é›†å›è°ƒæ•°æ®ï¼š{query.data}")
    # åŠ è½½çŠ¶æ€æç¤ºï¼ˆå·²æ³¨é‡Šï¼Œæ ¹æ®ç”¨æˆ·è¦æ±‚ä¸å½±å“æŒ‰é’®å±•ç¤ºï¼‰
    # await query.answer("å¤„ç†ä¸­...", show_alert=False)

    try:
        # ------------------------------
        # 1. ä¿®å¤ï¼šè§£æå›è°ƒæ•°æ®ï¼ˆå…¼å®¹å‹ç¼©åçš„çŸ­IDï¼‰
        # ------------------------------
        try:
            # è§£æå›è°ƒæ•°æ®ï¼ˆå…¼å®¹æ–°æ—§æ ¼å¼ï¼‰
            callback_data = json.loads(query.data)
            # æ”¯æŒæ–°æ ¼å¼ï¼ˆçŸ­å­—æ®µåï¼‰å’Œæ—§æ ¼å¼ï¼ˆå®Œæ•´å­—æ®µåï¼‰
            action = callback_data.get("a") or callback_data.get("action")
            data_id = callback_data.get("d") or callback_data.get("data_id")
            current_page = int(callback_data.get("p", callback_data.get("current_page", 1)))
            logger.info(f"ğŸ” è§£æå›è°ƒæ•°æ® - action: '{action}', data_id: '{data_id}', current_page: {current_page}")
            logger.info(f"ğŸ” åŸå§‹å›è°ƒæ•°æ®: {query.data}")
        except (json.JSONDecodeError, ValueError, TypeError):
            await query.answer("âŒ æ“ä½œå·²è¿‡æœŸï¼Œè¯·é‡æ–°è·å–åˆ†é›†", show_alert=True)
            return ConversationHandler.END

        # æ ¡éªŒæ ¸å¿ƒå‚æ•°
        valid_actions = ["get_media_episode", "get_episodes", "switch_episode_page", "start_input_range"]
        if action not in valid_actions or not data_id:
            await query.answer("âŒ æ— æ•ˆæ“ä½œï¼Œè¯·é‡æ–°è·å–åˆ†é›†", show_alert=True)
            return ConversationHandler.END

        # ------------------------------
        # 2. åˆå§‹åŒ–ä¸Šä¸‹æ–‡ç¼“å­˜ï¼ˆæ–°å¢ï¼šçŸ­IDä¸åŸå§‹æ•°æ®çš„æ˜ å°„ï¼‰
        # ------------------------------
        # ç¼“å­˜ç»“æ„ï¼š
        # context.user_data["episode_data_map"] = {
        #     "çŸ­ID": {
        #         "result_index": åŸå§‹result_index,
        #         "search_id": åŸå§‹search_id,
        #         "total_episodes": æ€»é›†æ•°,
        #         "cached_episodes": å…¨é‡åˆ†é›†åˆ—è¡¨
        #     }
        # }
        if "episode_data_map" not in context.user_data:
            context.user_data["episode_data_map"] = {}
        episode_data_map = context.user_data["episode_data_map"]

        # ä»çŸ­IDæ˜ å°„ä¸­è·å–åŸå§‹æ•°æ®ï¼ˆæ— åˆ™æç¤ºé‡æ–°è·å–ï¼‰
        if data_id not in episode_data_map and action != "get_media_episode":
            await query.answer("âŒ æ•°æ®å·²è¿‡æœŸï¼Œè¯·é‡æ–°è·å–åˆ†é›†", show_alert=True)
            return ConversationHandler.END

        # ------------------------------
        # 3. é¦–æ¬¡è·å–åˆ†é›†ï¼šè°ƒç”¨æ¥å£+ç”ŸæˆçŸ­IDï¼ˆæ ¸å¿ƒä¿®å¤ï¼šé¿å…é•¿æ•°æ®ï¼‰
        # ------------------------------
        if action == "get_media_episode":
            # é¦–æ¬¡è·å–æ—¶ï¼Œdata_idæš‚å­˜åŸå§‹result_indexï¼ˆç”¨äºç”ŸæˆçŸ­IDï¼‰
            try:
                result_index = int(data_id)
                search_id = context.user_data.get("search_id", "")
                logger.info(f"ğŸ” è·å–åˆ†é›†è¯·æ±‚ - result_index: {result_index}, search_id: {search_id}")
                logger.info(f"ğŸ” å½“å‰ç”¨æˆ·æ•°æ®: {list(context.user_data.keys())}")
                if not search_id:
                    logger.warning(f"âŒ æœªæ‰¾åˆ°search_idï¼Œç”¨æˆ·æ•°æ®: {context.user_data}")
                    await query.answer("âŒ æœªæ‰¾åˆ°æœç´¢è®°å½•ï¼Œè¯·é‡æ–°æœç´¢", show_alert=True)
                    return ConversationHandler.END
            except ValueError:
                await query.answer("âŒ æ— æ•ˆå‚æ•°ï¼Œè¯·é‡æ–°è·å–åˆ†é›†", show_alert=True)
                return ConversationHandler.END

            # ç”¨æˆ·è¦æ±‚ï¼šç‚¹å‡»åˆ†é›†å¯¼å…¥æ—¶ä¸æ˜¾ç¤ºåŠ è½½çŠ¶æ€ï¼Œä¿ç•™åŸæŒ‰é’®çŠ¶æ€
            # æ³¨é‡Šæ‰åŠ è½½çŠ¶æ€æ›´æ–°é€»è¾‘
            # try:
            #     loading_keyboard = [[InlineKeyboardButton(text="â³ åŠ è½½åˆ†é›†ä¸­...", callback_data="empty")]]
            #     await query.edit_message_reply_markup(reply_markup=InlineKeyboardMarkup(loading_keyboard))
            # except BadRequest as e:
            #     logger.warning(f"âš ï¸ ç¼–è¾‘åŠ è½½æŒ‰é’®å¤±è´¥ï¼š{str(e)}")

            # è°ƒç”¨æ¥å£è·å–å…¨é‡åˆ†é›†
            logger.info(f"ğŸŒ è°ƒç”¨APIè·å–åˆ†é›† - searchId: {search_id}, result_index: {result_index}")
            api_result = call_danmaku_api(
                method="GET",
                endpoint="/episodes",
                params={"searchId": search_id, "result_index": result_index}
            )
            logger.info(f"ğŸŒ APIå“åº”: success={api_result.get('success')}, error={api_result.get('error', 'None')}")
            if api_result.get('success'):
                episodes_count = len(api_result.get('data', []))
                logger.info(f"ğŸŒ è·å–åˆ° {episodes_count} ä¸ªåˆ†é›†æ•°æ®")

            # å¤„ç†æ¥å£å“åº”
            if not api_result.get("success", False):
                error_msg = api_result.get("error", "æœªçŸ¥é”™è¯¯")
                # ç”Ÿæˆé‡æ–°è·å–çš„çŸ­å›è°ƒï¼ˆä½¿ç”¨åŸå§‹result_indexä½œä¸ºä¸´æ—¶data_idï¼‰
                retry_callback = json.dumps({
                    "action": "get_media_episode",
                    "data_id": str(result_index)  # ä¸´æ—¶ç”¨result_indexï¼Œé¦–æ¬¡è·å–åæ›¿æ¢ä¸ºçŸ­ID
                }, ensure_ascii=False)
                # æ ¡éªŒå›è°ƒé•¿åº¦ï¼ˆé¿å…å†æ¬¡æŠ¥é”™ï¼‰
                if len(retry_callback) > CALLBACK_DATA_MAX_LEN:
                    retry_callback = json.dumps({"action": "get_media_episode", "data_id": "retry"}, ensure_ascii=False)

                # ä¿ç•™åŸæœ‰çš„ä¸¤ä¸ªæŒ‰é’®
                fail_keyboard = [
                    [
                        InlineKeyboardButton(text="ğŸ”— ç«‹å³å¯¼å…¥", callback_data=json.dumps({"action": "import_media", "result_index": result_index}, ensure_ascii=False)),
                        InlineKeyboardButton(text="ğŸ“º åˆ†é›†å¯¼å…¥", callback_data=json.dumps({"action": "get_media_episode", "result_index": result_index}, ensure_ascii=False))
                    ]
                ]
                await query.edit_message_reply_markup(reply_markup=InlineKeyboardMarkup(fail_keyboard))
                await query.message.reply_text(f"âŒ åˆ†é›†è·å–å¤±è´¥ï¼š{error_msg}")
                return ConversationHandler.END

            # è¿‡æ»¤æ— æ•ˆåˆ†é›†ï¼ˆæ–°ç»“æ„å¿…ä¼ å­—æ®µï¼‰
            logger.info(f"ğŸ” å¼€å§‹è¿‡æ»¤åˆ†é›†æ•°æ®ï¼ŒåŸå§‹æ•°æ®æ•°é‡: {len(api_result.get('data', []))}")
            full_episodes = [
                ep for ep in api_result.get("data", [])
                if all(key in ep for key in ["provider", "episodeId", "title", "episodeIndex"])
            ]
            logger.info(f"ğŸ” è¿‡æ»¤åæœ‰æ•ˆåˆ†é›†æ•°é‡: {len(full_episodes)}")
            if not full_episodes:
                logger.warning(f"âš ï¸ æ²¡æœ‰æœ‰æ•ˆåˆ†é›†æ•°æ®")
                await query.message.reply_text("âŒ å½“å‰åª’ä½“æ— å¯ç”¨åˆ†é›†æ•°æ®")
                # ç”Ÿæˆé‡æ–°è·å–çš„çŸ­å›è°ƒ
                retry_callback = json.dumps({
                    "action": "get_media_episode",
                    "data_id": str(result_index)
                }, ensure_ascii=False)
                # ä¿ç•™åŸæœ‰çš„ä¸¤ä¸ªæŒ‰é’®
                empty_keyboard = [
                    [
                        InlineKeyboardButton(text="ğŸ”— ç«‹å³å¯¼å…¥", callback_data=json.dumps({"action": "import_media", "result_index": result_index}, ensure_ascii=False)),
                        InlineKeyboardButton(text="ğŸ“º åˆ†é›†å¯¼å…¥", callback_data=json.dumps({"action": "get_media_episode", "result_index": result_index}, ensure_ascii=False))
                    ]
                ]
                await query.edit_message_reply_markup(reply_markup=InlineKeyboardMarkup(empty_keyboard))
                return ConversationHandler.END

            # æ ¸å¿ƒä¿®å¤ï¼šç”ŸæˆçŸ­IDï¼ˆæ›¿ä»£é•¿result_index+searchIdï¼Œå‡å°‘å›è°ƒé•¿åº¦ï¼‰
            # ç”¨searchId+result_indexç”ŸæˆMD5ï¼Œå–å‰8ä½ä½œä¸ºçŸ­IDï¼ˆå†²çªæ¦‚ç‡æä½ï¼‰
            raw_data = f"{search_id}_{result_index}"
            short_id = hashlib.md5(raw_data.encode()).hexdigest()[:8]
            logger.info(f"ğŸ”‘ ç”ŸæˆçŸ­ID: {short_id}ï¼ŒåŸå§‹æ•°æ®: {raw_data}")
            
            # ä»æœç´¢ç»“æœä¸­è·å–å‰§é›†åŸºæœ¬ä¿¡æ¯
            search_results = context.user_data.get("search_results", [])
            selected_result = search_results[result_index] if result_index < len(search_results) else {}
            
            # ç¼“å­˜åŸå§‹æ•°æ®åˆ°çŸ­IDæ˜ å°„
            episode_data_map[short_id] = {
                "result_index": result_index,
                "search_id": search_id,
                "total_episodes": len(full_episodes),
                "cached_episodes": full_episodes,
                "type": selected_result.get('type', 'tv_series'),
                "title": selected_result.get('title', ''),
                "season": selected_result.get('season')
            }
            logger.info(f"ğŸ’¾ ç¼“å­˜åˆ†é›†æ•°æ®åˆ°çŸ­IDæ˜ å°„ï¼Œæ€»é›†æ•°: {len(full_episodes)}")
            
            # æ›´æ–°data_idä¸ºçŸ­IDï¼ˆåç»­æ“ä½œä½¿ç”¨ï¼‰
            data_id = short_id
            logger.info(f"ğŸ”„ æ›´æ–°data_idä¸ºçŸ­ID: {data_id}")
            
            # ç›´æ¥æ˜¾ç¤ºåˆ†é›†åˆ—è¡¨ï¼ˆç”¨æˆ·è¦æ±‚çš„ä¼˜åŒ–ï¼‰
            logger.info(f"ğŸ“‹ ç›´æ¥æ˜¾ç¤ºåˆ†é›†åˆ—è¡¨ï¼Œè·³è¿‡ä¸­é—´é€‰æ‹©æ­¥éª¤")
            
            # è®¡ç®—åˆ†é¡µå‚æ•°ï¼ˆç¬¬ä¸€é¡µï¼‰
            current_page = 1
            total_pages = (len(full_episodes) + EPISODES_PER_PAGE - 1) // EPISODES_PER_PAGE
            start_idx = 0
            end_idx = EPISODES_PER_PAGE
            current_page_episodes = full_episodes[start_idx:end_idx]
            
            # æ„å»ºåˆ†é›†è¯¦æƒ…
            page_info = f"ï¼ˆç¬¬{current_page}/{total_pages}é¡µï¼‰" if total_pages > 1 else ""
            episode_details = []
            for i, episode in enumerate(current_page_episodes, 1):
                provider = episode.get("provider", "æœªçŸ¥æ¥æº")
                episode_index = episode["episodeIndex"]
                episode_title = episode.get("title", f"ç¬¬{episode_index}é›†")
                episode_details.append(f"{i}. ã€ç¬¬{episode_index}é›†ã€‘{episode_title} ({provider})")
            
            episodes_text = "\n".join(episode_details)
            full_message = f"""âœ… å…±æ‰¾åˆ° {len(full_episodes)} é›†æœ‰æ•ˆåˆ†é›† {page_info}
ğŸ’¡ è¯·ç›´æ¥è¾“å…¥é›†æ•°åŒºé—´æˆ– allï¼š
   â€¢ å•é›†ï¼š1
   â€¢ åŒºé—´ï¼š1-10
   â€¢ å¤šé€‰ï¼š1,5,10
   â€¢ å…¨éƒ¨ï¼šall

ğŸ“º åˆ†é›†åˆ—è¡¨ï¼š
{episodes_text}"""
            
            # ç”Ÿæˆæ“ä½œæŒ‰é’®
            buttons = []
            
            # åˆ†é¡µæŒ‰é’®è¡Œï¼ˆä»…åœ¨å¤šé¡µæ—¶æ˜¾ç¤ºï¼‰
            if total_pages > 1:
                pagination_buttons = []
                # ä¸Šä¸€é¡µæŒ‰é’®
                if current_page > 1:
                    prev_callback = json.dumps({
                        "a": "switch_episode_page",
                        "d": data_id,
                        "p": current_page - 1
                    }, ensure_ascii=False)
                    if len(prev_callback) > CALLBACK_DATA_MAX_LEN:
                        safe_id_len = 17
                        prev_callback = json.dumps({
                            "a": "switch_episode_page",
                            "d": data_id[:safe_id_len],
                            "p": current_page - 1
                        }, ensure_ascii=False)
                    pagination_buttons.append(InlineKeyboardButton(text="â¬…ï¸ ä¸Šä¸€é¡µ", callback_data=prev_callback))

                # ä¸‹ä¸€é¡µæŒ‰é’®
                if current_page < total_pages:
                    next_callback = json.dumps({
                        "a": "switch_episode_page",
                        "d": data_id,
                        "p": current_page + 1
                    }, ensure_ascii=False)
                    if len(next_callback) > CALLBACK_DATA_MAX_LEN:
                        safe_id_len = 17
                        next_callback = json.dumps({
                            "a": "switch_episode_page",
                            "d": data_id[:safe_id_len],
                            "p": current_page + 1
                        }, ensure_ascii=False)
                    pagination_buttons.append(InlineKeyboardButton(text="ä¸‹ä¸€é¡µ â¡ï¸", callback_data=next_callback))
                
                if pagination_buttons:
                    buttons.append(pagination_buttons)
            
            # ä¸å†æ·»åŠ è¾“å…¥æŒ‰é’®å’Œå¯¼å…¥æŒ‰é’®ï¼Œç”¨æˆ·å¯ä»¥ç›´æ¥è¾“å…¥
            
            # å­˜å‚¨å½“å‰æ•°æ®IDä¾›è¾“å…¥å¤„ç†ä½¿ç”¨
            context.user_data["current_data_id"] = data_id
            
            logger.info(f"ğŸ“¤ å‘é€åˆ†é›†åˆ—è¡¨æ¶ˆæ¯ï¼Œæ€»é›†æ•°: {len(full_episodes)}, å½“å‰é¡µ: {current_page}/{total_pages}")
            await query.message.reply_text(
                text=full_message,
                reply_markup=InlineKeyboardMarkup(buttons) if buttons else None,
                parse_mode=None
            )
            logger.info(f"âœ… åˆ†é›†åˆ—è¡¨æ¶ˆæ¯å‘é€æˆåŠŸï¼Œè¿›å…¥é›†æ•°è¾“å…¥çŠ¶æ€")
            return INPUT_EPISODE_RANGE

        # ------------------------------
        # 4. åˆ†é¡µé¢„è§ˆé€»è¾‘ï¼ˆä½¿ç”¨çŸ­IDè·å–åŸå§‹æ•°æ®ï¼‰
        # ------------------------------
        # ä»çŸ­IDæ˜ å°„ä¸­è·å–åŸå§‹æ•°æ®
        current_data = episode_data_map.get(data_id, {})
        full_episodes = current_data.get("cached_episodes", [])
        total_episodes = current_data.get("total_episodes", 0)
        if not full_episodes or total_episodes == 0:
            await query.answer("âŒ æ•°æ®å·²è¿‡æœŸï¼Œè¯·é‡æ–°è·å–åˆ†é›†", show_alert=True)
            return ConversationHandler.END

        # ------------------------------
        # 5. è§¦å‘é›†æ•°è¾“å…¥æµç¨‹ï¼ˆç›´æ¥å¤„ç†ï¼Œä¸æ˜¾ç¤ºåˆ†é¡µï¼‰
        # ------------------------------
        if action == "start_input_range":
            # å­˜å‚¨å½“å‰çŸ­IDï¼ˆä¾›è¾“å…¥å¤„ç†å‡½æ•°ä½¿ç”¨ï¼‰
            context.user_data["current_data_id"] = data_id
            await query.message.reply_text(
                f"ğŸ“ è¯·è¾“å…¥éœ€è¦å¯¼å…¥çš„é›†æ•°ï¼ˆå½“å‰å…±{total_episodes}é›†ï¼‰ï¼š\n\n"
                f"ğŸ’¡ **æ”¯æŒæ ¼å¼ï¼š**\n"
                f"â€¢ å•ä¸ªé›†æ•°ï¼šå¦‚ `5`\n"
                f"â€¢ é›†æ•°åŒºé—´ï¼šå¦‚ `1-10` æˆ– `5,8,12`\n"
                f"â€¢ å…¨éƒ¨åˆ†é›†ï¼šè¾“å…¥ `all`",
                parse_mode="Markdown"
            )
            return INPUT_EPISODE_RANGE

        # å¤„ç†get_episodesåŠ¨ä½œï¼šç›´æ¥è¿›å…¥è¾“å…¥çŠ¶æ€ï¼ˆç”¨æˆ·è¦æ±‚çš„ä¼˜åŒ–ï¼‰
        elif action == "get_episodes":
            logger.info(f"ğŸ“‹ å¤„ç†è·å–åˆ†é›†è¯·æ±‚ï¼Œç›´æ¥è¿›å…¥è¾“å…¥çŠ¶æ€")
            # å­˜å‚¨å½“å‰çŸ­IDï¼ˆä¾›è¾“å…¥å¤„ç†å‡½æ•°ä½¿ç”¨ï¼‰
            context.user_data["current_data_id"] = data_id
            await query.message.reply_text(
                f"ğŸ“ è¯·è¾“å…¥éœ€è¦å¯¼å…¥çš„é›†æ•°ï¼ˆå½“å‰å…±{total_episodes}é›†ï¼‰ï¼š\n\n"
                f"ğŸ’¡ **æ”¯æŒæ ¼å¼ï¼š**\n"
                f"â€¢ å•ä¸ªé›†æ•°ï¼šå¦‚ `5`\n"
                f"â€¢ é›†æ•°åŒºé—´ï¼šå¦‚ `1-10` æˆ– `5,8,12`\n"
                f"â€¢ å…¨éƒ¨åˆ†é›†ï¼šè¾“å…¥ `all`",
                parse_mode="Markdown"
            )
            return INPUT_EPISODE_RANGE
        
        # å¤„ç†åˆ†é¡µæ˜¾ç¤ºé€»è¾‘ï¼ˆä»…åœ¨ç¿»é¡µæ—¶æ‰§è¡Œï¼‰
        elif action == "switch_episode_page":
            logger.info(f"ğŸ“‹ è¿›å…¥åˆ†é¡µæ˜¾ç¤ºé€»è¾‘ï¼Œaction: {action}, data_id: {data_id}")
            logger.info(f"ğŸ“„ å¤„ç†ç¿»é¡µè¯·æ±‚ï¼šåˆ‡æ¢åˆ°ç¬¬{current_page}é¡µ")

            # è®¡ç®—åˆ†é¡µå‚æ•°
            total_pages = (total_episodes + EPISODES_PER_PAGE - 1) // EPISODES_PER_PAGE
            current_page = max(1, min(current_page, total_pages))  # ä¿®æ­£éæ³•é¡µç 
            start_idx = (current_page - 1) * EPISODES_PER_PAGE
            end_idx = start_idx + EPISODES_PER_PAGE
            current_page_episodes = full_episodes[start_idx:end_idx]

            # 4.1 æ„å»ºåˆ†é›†è¯¦æƒ…ï¼ˆ1æ¡æ¶ˆæ¯æ˜¾ç¤º10ä¸ªåˆ†é›†ï¼‰
            page_info = f"ï¼ˆç¬¬{current_page}/{total_pages}é¡µï¼‰" if total_pages > 1 else ""
            episode_details = []
            for i, episode in enumerate(current_page_episodes, 1):
                provider = episode.get("provider", "æœªçŸ¥æ¥æº")
                episode_index = episode["episodeIndex"]
                episode_title = episode.get("title", f"ç¬¬{episode_index}é›†")
                episode_details.append(f"{i}. ã€ç¬¬{episode_index}é›†ã€‘{episode_title} ({provider})")
            
            episodes_text = "\n".join(episode_details)
            # 4.2 ç”Ÿæˆåˆ†é¡µå’Œè¾“å…¥æŒ‰é’®ï¼ˆæŒ‰éœ€æ˜¾ç¤ºï¼‰
            buttons = []
            
            # åˆ†é¡µæŒ‰é’®è¡Œï¼ˆä»…åœ¨å¤šé¡µæ—¶æ˜¾ç¤ºï¼‰
            if total_pages > 1:
                pagination_buttons = []
                # ä¸Šä¸€é¡µæŒ‰é’®ï¼ˆä½¿ç”¨çŸ­å­—æ®µåï¼‰
                if current_page > 1:
                    prev_callback = json.dumps({
                        "a": "switch_episode_page",  # actionç¼©å†™
                        "d": data_id,  # data_idç¼©å†™
                        "p": current_page - 1  # current_pageç¼©å†™
                    }, ensure_ascii=False)
                    # å›è°ƒé•¿åº¦æ ¡éªŒå’Œæˆªæ–­å¤„ç†
                    if len(prev_callback) > CALLBACK_DATA_MAX_LEN:
                        logger.warning(f"âš ï¸ ä¸Šä¸€é¡µå›è°ƒè¿‡é•¿({len(prev_callback)})ï¼Œæˆªæ–­data_id")
                        # è®¡ç®—å®‰å…¨çš„data_idé•¿åº¦
                        safe_id_len = max(4, 17)  # åŸºäºæµ‹è¯•ç»“æœï¼Œåˆ†é¡µæŒ‰é’®æœ€å¤š17å­—ç¬¦
                        prev_callback = json.dumps({
                            "a": "switch_episode_page",
                            "d": data_id[:safe_id_len],
                            "p": current_page - 1
                        }, ensure_ascii=False)
                        logger.info(f"âœ… æˆªæ–­åå›è°ƒé•¿åº¦ï¼š{len(prev_callback)}")
                    pagination_buttons.append(InlineKeyboardButton(text="â¬…ï¸ ä¸Šä¸€é¡µ", callback_data=prev_callback))

                # ç§»é™¤é¡µç æ˜¾ç¤ºæŒ‰é’®ï¼Œä¼˜åŒ–ç•Œé¢ç®€æ´æ€§

                # ä¸‹ä¸€é¡µæŒ‰é’®ï¼ˆä½¿ç”¨çŸ­å­—æ®µåï¼‰
                if current_page < total_pages:
                    next_callback = json.dumps({
                        "a": "switch_episode_page",
                        "d": data_id,
                        "p": current_page + 1
                    }, ensure_ascii=False)
                    if len(next_callback) > CALLBACK_DATA_MAX_LEN:
                        logger.warning(f"âš ï¸ ä¸‹ä¸€é¡µå›è°ƒè¿‡é•¿({len(next_callback)})ï¼Œæˆªæ–­data_id")
                        safe_id_len = max(4, 17)  # åˆ†é¡µæŒ‰é’®å®‰å…¨é•¿åº¦
                        next_callback = json.dumps({
                            "a": "switch_episode_page",
                            "d": data_id[:safe_id_len],
                            "p": current_page + 1
                        }, ensure_ascii=False)
                        logger.info(f"âœ… æˆªæ–­åå›è°ƒé•¿åº¦ï¼š{len(next_callback)}")
                    pagination_buttons.append(InlineKeyboardButton(text="ä¸‹ä¸€é¡µ â¡ï¸", callback_data=next_callback))
                
                buttons.append(pagination_buttons)
            
            # ç§»é™¤è¾“å…¥é›†æ•°åŒºé—´å’Œç«‹å³å¯¼å…¥å…¨éƒ¨æŒ‰é’®ï¼ˆç”¨æˆ·è¦æ±‚çš„ä¼˜åŒ–ï¼‰
            # åˆ†é¡µæ˜¾ç¤ºæ—¶åªä¿ç•™åˆ†é¡µæŒ‰é’®ï¼Œç”¨æˆ·å¯ç›´æ¥è¾“å…¥é›†æ•°
            
            full_message = f"""âœ… å…±æ‰¾åˆ° {total_episodes} é›†æœ‰æ•ˆåˆ†é›† {page_info}

ğŸ’¡ **æ”¯æŒè¾“å…¥æ ¼å¼ï¼š**
â€¢ å•ä¸ªé›†æ•°ï¼šå¦‚ `5`
â€¢ é›†æ•°åŒºé—´ï¼šå¦‚ `1-10` æˆ– `5,8,12`
â€¢ å…¨éƒ¨åˆ†é›†ï¼šè¾“å…¥ `all`

ğŸ“º åˆ†é›†åˆ—è¡¨ï¼š
{episodes_text}"""
            
            # å‘é€åˆ†é›†åˆ—è¡¨æ¶ˆæ¯å’ŒæŒ‰é’®ï¼ˆä¸€æ¬¡æ€§å‘é€ï¼‰
            keyboard = InlineKeyboardMarkup(buttons) if buttons else None
            logger.info(f"ğŸ“¤ å‘é€åˆ†é›†åˆ—è¡¨æ¶ˆæ¯ï¼Œæ€»é›†æ•°: {total_episodes}, å½“å‰é¡µ: {current_page}/{total_pages}, æŒ‰é’®æ•°é‡: {len(buttons)}")
            await query.edit_message_text(
                text=full_message,
                reply_markup=keyboard,
                parse_mode=None
            )
            logger.info(f"âœ… åˆ†é›†åˆ—è¡¨æ¶ˆæ¯å’ŒæŒ‰é’®å‘é€æˆåŠŸ")
            # ä¿æŒä¼šè¯çŠ¶æ€ï¼Œå…è®¸ç”¨æˆ·ç›´æ¥è¾“å…¥é›†æ•°
            context.user_data["current_data_id"] = data_id
            return INPUT_EPISODE_RANGE

    except BadRequest as e:
        # æ•è·TelegramæŒ‰é’®ç›¸å…³é”™è¯¯ï¼ˆå¦‚Button_data_invalidï¼‰
        logger.error(f"âŒ æŒ‰é’®å›è°ƒé”™è¯¯ï¼š{str(e)}ï¼ˆå½“å‰å›è°ƒé•¿åº¦ï¼š{len(query.data) if query.data else 0}ï¼‰", exc_info=True)
        await query.answer("âŒ æ“ä½œå¤±è´¥ï¼Œè¯·é‡æ–°è·å–åˆ†é›†", show_alert=True)
        # æ¢å¤åŸºç¡€æŒ‰é’®ï¼ˆä½¿ç”¨æœ€çŸ­å›è°ƒï¼‰
        if "data_id" in locals():
            try:
                retry_callback = json.dumps({"action": "get_media_episode", "data_id": data_id[:6]}, ensure_ascii=False)
                # ä¿ç•™åŸæœ‰çš„ä¸¤ä¸ªæŒ‰é’®
                error_keyboard = [
                    [
                        InlineKeyboardButton(text="ğŸ”— ç«‹å³å¯¼å…¥", callback_data=json.dumps({"action": "import_media", "data_id": data_id}, ensure_ascii=False)),
                        InlineKeyboardButton(text="ğŸ“º åˆ†é›†å¯¼å…¥", callback_data=json.dumps({"action": "get_media_episode", "data_id": data_id}, ensure_ascii=False))
                    ]
                ]
                await query.edit_message_reply_markup(reply_markup=InlineKeyboardMarkup(error_keyboard))
            except Exception:
                pass
    except Exception as e:
        logger.error(f"âŒ åˆ†é›†å¤„ç†å¼‚å¸¸ï¼š{str(e)}", exc_info=True)
        await query.answer("âŒ å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•", show_alert=True)
        if "data_id" in locals():
            try:
                retry_callback = json.dumps({"action": "get_media_episode", "data_id": data_id[:6]}, ensure_ascii=False)
                # ä¿ç•™åŸæœ‰çš„ä¸¤ä¸ªæŒ‰é’®
                error_keyboard = [
                    [
                        InlineKeyboardButton(text="ğŸ”— ç«‹å³å¯¼å…¥", callback_data=json.dumps({"action": "import_media", "data_id": data_id}, ensure_ascii=False)),
                        InlineKeyboardButton(text="ğŸ“º åˆ†é›†å¯¼å…¥", callback_data=json.dumps({"action": "get_media_episode", "data_id": data_id}, ensure_ascii=False))
                    ]
                ]
                await query.edit_message_reply_markup(reply_markup=InlineKeyboardMarkup(error_keyboard))
            except Exception:
                pass

    return ConversationHandler.END


# ------------------------------
# é›†æ•°è¾“å…¥å¤„ç†ï¼ˆé€‚é…çŸ­IDï¼‰
# ------------------------------
@check_user_permission
async def handle_episode_range_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text.strip()
    logger.info(f"ğŸ“¥ æ”¶åˆ°é›†æ•°åŒºé—´è¾“å…¥ï¼š{user_input}")

    # ä»çŸ­IDæ˜ å°„ä¸­è·å–åŸå§‹æ•°æ®ï¼ˆé€‚é…ä¿®å¤ï¼‰
    current_data_id = context.user_data.get("current_data_id")
    episode_data_map = context.user_data.get("episode_data_map", {})
    current_data = episode_data_map.get(current_data_id, {})

    # æ ¡éªŒæ•°æ®ï¼ˆé€‚é…çŸ­IDï¼‰
    full_episodes = current_data.get("cached_episodes", [])
    total_episodes = current_data.get("total_episodes", 0)
    if not current_data_id or current_data_id not in episode_data_map or not full_episodes:
        await update.message.reply_text("âŒ æ•°æ®å·²è¿‡æœŸï¼Œè¯·é‡æ–°è·å–åˆ†é›†")
        return ConversationHandler.END

    # è§£æé›†æ•°ï¼ˆæ”¯æŒallé€‰é¡¹ï¼‰
    episode_index_map = {ep["episodeIndex"]: ep for ep in full_episodes}
    valid_episode_indices = set(episode_index_map.keys())
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºå…¨éƒ¨å¯¼å…¥
    if user_input.lower() == 'all':
        selected_indices = valid_episode_indices
        await update.message.reply_text(
            f"âœ… å·²é€‰æ‹©å¯¼å…¥å…¨éƒ¨ {len(selected_indices)} é›†\n"
            f"ğŸ’¡ å³å°†å¼€å§‹å¯¼å…¥"
        )
    else:
        range_segments = [seg.strip() for seg in user_input.split(",") if seg.strip()]

        if not range_segments:
            await update.message.reply_text("âŒ è¾“å…¥ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥\nğŸ’¡ æ”¯æŒæ ¼å¼ï¼š\nâ€¢ å•ä¸ªé›†æ•°ï¼šå¦‚ 5\nâ€¢ é›†æ•°åŒºé—´ï¼šå¦‚ 1-10 æˆ– 5,8,12\nâ€¢ å…¨éƒ¨åˆ†é›†ï¼šè¾“å…¥ all")
            return INPUT_EPISODE_RANGE

        selected_indices = set()
        invalid_segments = []
        for seg in range_segments:
            if "-" in seg:
                try:
                    start, end = map(int, [s.strip() for s in seg.split("-", 1)])
                    if start > end:
                        start, end = end, start
                    segment_indices = set(range(start, end + 1))
                except (ValueError, IndexError):
                    invalid_segments.append(seg)
                    continue
            else:
                try:
                    segment_indices = {int(seg)}
                except ValueError:
                    invalid_segments.append(seg)
                    continue

            valid_in_segment = segment_indices & valid_episode_indices
            selected_indices.update(valid_in_segment)
            invalid_in_segment = segment_indices - valid_episode_indices
            if invalid_in_segment:
                invalid_segments.append(f"{seg}ï¼ˆæ— æ•ˆé›†æ•°ï¼š{sorted(invalid_in_segment)}ï¼‰")
            
        if not selected_indices:
            msg = "âŒ æœªæ‰¾åˆ°æœ‰æ•ˆé›†æ•°ï¼Œè¯·é‡æ–°è¾“å…¥\n"
            if invalid_segments:
                msg += f"æ— æ•ˆç‰‡æ®µï¼š{', '.join(invalid_segments)}\n"
            msg += f"å½“å‰æ”¯æŒé›†æ•°ï¼š1-{total_episodes}\nğŸ’¡ æ”¯æŒæ ¼å¼ï¼š\nâ€¢ å•ä¸ªé›†æ•°ï¼šå¦‚ 5\nâ€¢ é›†æ•°åŒºé—´ï¼šå¦‚ 1-10 æˆ– 5,8,12\nâ€¢ å…¨éƒ¨åˆ†é›†ï¼šè¾“å…¥ all"
            await update.message.reply_text(msg)
            return INPUT_EPISODE_RANGE

        # æ˜¾ç¤ºé€‰ä¸­ç»“æœ
        sorted_indices = sorted(selected_indices)
        # await update.message.reply_text(
        #     f"âœ… å…±é€‰ä¸­ {len(sorted_indices)} é›†ï¼š\n"
        #     f"é€‰ä¸­é›†æ•°ï¼š{', '.join(map(str, sorted_indices))}\n"
        #     f"ğŸ’¡ å³å°†å¼€å§‹å¯¼å…¥"
        # )


    # å‡†å¤‡å¯¼å…¥
    sorted_indices = sorted(selected_indices)

    # è°ƒç”¨/import/editedæ¥å£å¯¼å…¥é€‰ä¸­çš„é›†æ•°
    try:
        # æ„å»ºepisodeså‚æ•°ï¼šåŒ…å«é€‰ä¸­é›†æ•°çš„è¯¦ç»†ä¿¡æ¯
        episodes_to_import = []
        for idx in sorted_indices:
            ep = episode_index_map[idx]
            episodes_to_import.append({
                "provider": ep.get("provider"),
                "episodeId": ep.get("episodeId"),
                "title": ep.get("title"),
                "episodeIndex": ep.get("episodeIndex")
            })
        
        # è·å–åŸå§‹æ•°æ®ç”¨äºAPIè°ƒç”¨
        result_index = current_data.get("result_index")
        search_id = current_data.get("search_id")
        
        # è°ƒç”¨/import/editedæ¥å£
        api_result = call_danmaku_api(
            method="POST",
            endpoint="/import/edited",
            json_data={
                "searchId": search_id,
                "result_index": result_index,
                "episodes": episodes_to_import
            }
        )
        
        # å¤„ç†å¯¼å…¥ç»“æœ
        if api_result.get("success", False):
            data = api_result.get("data", {})
            task_id = data.get('taskId')
            
            await update.message.reply_text(
                f"ğŸ‰ å¯¼å…¥è¯·æ±‚å·²æäº¤æˆåŠŸï¼\n"
                f"ä»»åŠ¡IDï¼š{task_id or 'æ— '}\n"
                f"å…±é€‰ä¸­ {len(sorted_indices)} é›†\n"
                f"é€‰ä¸­é›†æ•°ï¼š{', '.join(map(str, sorted_indices))}"
            )

            # å¦‚æœæœ‰taskIdï¼Œå¯åŠ¨è½®è¯¢å¹¶å‘é€å›è°ƒé€šçŸ¥
            if task_id:
                from utils.task_polling import bot_task_polling_manager
                
                # æ„å»ºåª’ä½“ä¿¡æ¯ï¼ˆä»current_dataè·å–ï¼Œé¿å…é‡å¤æŸ¥è¯¢search_resultsï¼‰
                media_info = {
                    'Type': current_data.get('type', 'tv_series'),
                    'Title': current_data.get('title', ''),
                    'Season': current_data.get('season'),
                }
                
                # å‘é€å›è°ƒé€šçŸ¥å¹¶å¯åŠ¨è½®è¯¢
                await bot_task_polling_manager.send_callback_notification(
                    operation_type="import",
                    media_info=media_info,
                    result="success",
                    task_ids=[task_id],
                    user_id=str(update.effective_user.id),
                    import_method="direct"  # åˆ†é›†å¯¼å…¥ä¸ºdirectæ–¹å¼
                )
        else:
            error_msg = api_result.get("error", "æœªçŸ¥é”™è¯¯")
            await update.message.reply_text(
                f"âŒ æ‰¹é‡å¯¼å…¥å¤±è´¥ï¼š{error_msg}\n"
                f"â€¢ å»ºè®®ï¼šè‹¥å¤šæ¬¡å¤±è´¥ï¼Œå¯å°è¯•é‡æ–°è·å–åˆ†é›†åå¯¼å…¥"
            )
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡å¯¼å…¥å¼‚å¸¸ï¼š{str(e)}", exc_info=True)
        await update.message.reply_text(
            f"âŒ å¯¼å…¥è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸ï¼š{str(e)}\n"
            f"â€¢ å»ºè®®ï¼šè¯·é‡æ–°è·å–åˆ†é›†åé‡è¯•"
        )

    return ConversationHandler.END


# ------------------------------
# å–æ¶ˆè¾“å…¥æµç¨‹ï¼ˆä¸å˜ï¼‰
# ------------------------------
@check_user_permission
async def cancel_episode_input(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ğŸ›‘ å·²å–æ¶ˆé›†æ•°è¾“å…¥")
    # æ¸…ç©ºä¸´æ—¶æ•°æ®
    for key in ["current_result_index", "total_episodes"]:
        if key in context.user_data:
            del context.user_data[key]
    return ConversationHandler.END


# ------------------------------
# ç»§ç»­å¯¼å…¥ç›¸å…³å¤„ç†å‡½æ•°
# ------------------------------
# å·²ç§»é™¤handle_continue_season_importå’Œhandle_continue_episode_importå‡½æ•°ï¼Œå› ä¸ºä¸å†éœ€è¦åˆ†å­£å¯¼å…¥å’Œåˆ†é›†å¯¼å…¥åŠŸèƒ½


@check_user_permission
async def handle_finish_import(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†å®Œæˆå¯¼å…¥"""
    query = update.callback_query
    await query.edit_message_text("âœ… å¯¼å…¥æµç¨‹å·²å®Œæˆï¼")
    
    # æ¸…ç†ä¸Šä¸‹æ–‡æ•°æ®
    keys_to_clear = [
        "import_auto_params", "import_auto_season", "import_auto_episode",
        "import_auto_episode_mode"
    ]
    for key in keys_to_clear:
        context.user_data.pop(key, None)
    
    return ConversationHandler.END





async def show_paged_results(update_or_query, context, search_results, page=0, per_page=5):
    """æ˜¾ç¤ºåˆ†é¡µçš„æœç´¢ç»“æœ"""
    results_per_page = per_page  # æ¯é¡µæ˜¾ç¤ºç»“æœæ•°é‡
    search_id = context.user_data.get("search_id", "")
    total_pages = (len(search_results) + results_per_page - 1) // results_per_page
    
    # è®¡ç®—å½“å‰é¡µçš„ç»“æœèŒƒå›´
    start_idx = page * results_per_page
    end_idx = min(start_idx + results_per_page, len(search_results))
    current_results = search_results[start_idx:end_idx]
    
    # ä¿å­˜åˆ†é¡µä¿¡æ¯åˆ°ä¸Šä¸‹æ–‡
    context.user_data["search_page"] = page
    context.user_data["search_total_pages"] = total_pages
    
    # å‘é€å½“å‰é¡µçš„ç»“æœ
    for idx, item in enumerate(current_results):
        actual_idx = start_idx + idx
        result_text = f"""ã€{actual_idx + 1}/{len(search_results)}ã€‘{item.get('title', 'æœªçŸ¥åç§°')}
â€¢ ç±»å‹ï¼š{item.get('type', 'æœªçŸ¥ç±»å‹')} | æ¥æºï¼š{item.get('provider', 'æœªçŸ¥æ¥æº')}
â€¢ å¹´ä»½ï¼š{item.get('year', 'æœªçŸ¥å¹´ä»½')} | å­£åº¦ï¼š{item.get('season', 'æœªçŸ¥å­£åº¦')}
â€¢ æ€»é›†æ•°ï¼š{item.get('episodeCount', '0')}é›†"""
        
        # æ„é€ å›è°ƒæ•°æ®
        callback_data_import = json.dumps({
            "action": "import_media",
            "result_index": actual_idx
        }, ensure_ascii=False)
        
        callback_data_episode = json.dumps({
            "action": "get_media_episode",
            "data_id": str(actual_idx)
        }, ensure_ascii=False)
        
        # ç”Ÿæˆå†…è”é”®ç›˜
        keyboard = [
            [InlineKeyboardButton(
                text="ğŸ”— ç«‹å³å¯¼å…¥",
                callback_data=callback_data_import
            ),
            InlineKeyboardButton(
                text="ğŸ“º åˆ†é›†å¯¼å…¥",
                callback_data=callback_data_episode
            )]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        # å‘é€ç»“æœæ¶ˆæ¯
        if hasattr(update_or_query, 'message'):  # è¿™æ˜¯ä¸€ä¸ªUpdateå¯¹è±¡
            await update_or_query.message.reply_text(
                text=result_text,
                reply_markup=reply_markup,
                parse_mode=None
            )
        else:  # è¿™æ˜¯ä¸€ä¸ªCallbackQueryå¯¹è±¡
            await update_or_query.message.reply_text(
                text=result_text,
                reply_markup=reply_markup,
                parse_mode=None
            )
    
    # å‘é€åˆ†é¡µæ§åˆ¶æ¶ˆæ¯
    page_text = f"ğŸ“„ ç¬¬ {page + 1}/{total_pages} é¡µ | å…± {len(search_results)} ä¸ªç»“æœ"
    page_keyboard = []
    
    # åˆ†é¡µæŒ‰é’®
    nav_row = []
    if page > 0:
        nav_row.append(InlineKeyboardButton(
            "â¬…ï¸ ä¸Šä¸€é¡µ",
            callback_data=json.dumps({"action": "search_page", "page": page - 1}, ensure_ascii=False)
        ))
    if page < total_pages - 1:
        nav_row.append(InlineKeyboardButton(
            "ä¸‹ä¸€é¡µ â¡ï¸",
            callback_data=json.dumps({"action": "search_page", "page": page + 1}, ensure_ascii=False)
        ))
    if nav_row:
        page_keyboard.append(nav_row)
    
    page_reply_markup = InlineKeyboardMarkup(page_keyboard) if page_keyboard else None
    
    # å‘é€åˆ†é¡µæ§åˆ¶æ¶ˆæ¯
    if hasattr(update_or_query, 'message'):  # è¿™æ˜¯ä¸€ä¸ªUpdateå¯¹è±¡
        if page_reply_markup:
            await update_or_query.message.reply_text(
                text=page_text,
                reply_markup=page_reply_markup
            )
        else:
            await update_or_query.message.reply_text(text=page_text)
    else:  # è¿™æ˜¯ä¸€ä¸ªCallbackQueryå¯¹è±¡
        try:
            await update_or_query.edit_message_text(
                text=page_text,
                reply_markup=page_reply_markup
            )
        except Exception as e:
            logger.error(f"ç¼–è¾‘åˆ†é¡µæ¶ˆæ¯å¤±è´¥: {e}")
            if page_reply_markup:
                await update_or_query.message.reply_text(
                    text=page_text,
                    reply_markup=page_reply_markup
                )
            else:
                await update_or_query.message.reply_text(text=page_text)


@check_user_permission
async def handle_search_page(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†æœç´¢ç»“æœç¿»é¡µ"""
    query = update.callback_query
    
    try:
        callback_data = json.loads(query.data)
        page = callback_data.get("page", 0)
        
        # è·å–æœç´¢ç»“æœ
        search_results = context.user_data.get("search_results", [])
        
        if not search_results:
            await query.answer("âŒ æœªæ‰¾åˆ°æœç´¢ç»“æœï¼Œè¯·é‡æ–°æœç´¢", show_alert=True)
            return
        
        await query.answer(f"ğŸ“„ è·³è½¬åˆ°ç¬¬ {page + 1} é¡µ")
        await show_paged_results(query, context, search_results, page, 5)
        
    except json.JSONDecodeError:
        await query.answer("âŒ æ•°æ®è§£æå¤±è´¥", show_alert=True)
    except Exception as e:
        logger.error(f"å¤„ç†ç¿»é¡µå¤±è´¥: {e}")
        await query.answer("âŒ ç¿»é¡µå¤±è´¥ï¼Œè¯·é‡è¯•", show_alert=True)